{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.4</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.7</td>\n",
       "      <td>3.53</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.2</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.4</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length   height   width\n",
       "0     8.4     2.11    1.41\n",
       "1    13.7     3.53    2.00\n",
       "2    15.0     3.82    2.43\n",
       "3    16.2     4.59    2.63\n",
       "4    17.4     4.59    2.94"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import statsmodels\n",
    "# df= pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/adp/22/content.csv')\n",
    "df = pd.read_csv('./Data/fish.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module statsmodels.regression.mixed_linear_model in statsmodels.regression:\n",
      "\n",
      "NAME\n",
      "    statsmodels.regression.mixed_linear_model\n",
      "\n",
      "DESCRIPTION\n",
      "    Linear mixed effects models are regression models for dependent data.\n",
      "    They can be used to estimate regression relationships involving both\n",
      "    means and variances.\n",
      "    \n",
      "    These models are also known as multilevel linear models, and\n",
      "    hierarchical linear models.\n",
      "    \n",
      "    The MixedLM class fits linear mixed effects models to data, and\n",
      "    provides support for some common post-estimation tasks.  This is a\n",
      "    group-based implementation that is most efficient for models in which\n",
      "    the data can be partitioned into independent groups.  Some models with\n",
      "    crossed effects can be handled by specifying a model with a single\n",
      "    group.\n",
      "    \n",
      "    The data are partitioned into disjoint groups.  The probability model\n",
      "    for group i is:\n",
      "    \n",
      "    Y = X*beta + Z*gamma + epsilon\n",
      "    \n",
      "    where\n",
      "    \n",
      "    * n_i is the number of observations in group i\n",
      "    \n",
      "    * Y is a n_i dimensional response vector (called endog in MixedLM)\n",
      "    \n",
      "    * X is a n_i x k_fe dimensional design matrix for the fixed effects\n",
      "      (called exog in MixedLM)\n",
      "    \n",
      "    * beta is a k_fe-dimensional vector of fixed effects parameters\n",
      "      (called fe_params in MixedLM)\n",
      "    \n",
      "    * Z is a design matrix for the random effects with n_i rows (called\n",
      "      exog_re in MixedLM).  The number of columns in Z can vary by group\n",
      "      as discussed below.\n",
      "    \n",
      "    * gamma is a random vector with mean 0.  The covariance matrix for the\n",
      "      first `k_re` elements of `gamma` (called cov_re in MixedLM) is\n",
      "      common to all groups.  The remaining elements of `gamma` are\n",
      "      variance components as discussed in more detail below. Each group\n",
      "      receives its own independent realization of gamma.\n",
      "    \n",
      "    * epsilon is a n_i dimensional vector of iid normal\n",
      "      errors with mean 0 and variance sigma^2; the epsilon\n",
      "      values are independent both within and between groups\n",
      "    \n",
      "    Y, X and Z must be entirely observed.  beta, Psi, and sigma^2 are\n",
      "    estimated using ML or REML estimation, and gamma and epsilon are\n",
      "    random so define the probability model.\n",
      "    \n",
      "    The marginal mean structure is E[Y | X, Z] = X*beta.  If only the mean\n",
      "    structure is of interest, GEE is an alternative to using linear mixed\n",
      "    models.\n",
      "    \n",
      "    Two types of random effects are supported.  Standard random effects\n",
      "    are correlated with each other in arbitrary ways.  Every group has the\n",
      "    same number (`k_re`) of standard random effects, with the same joint\n",
      "    distribution (but with independent realizations across the groups).\n",
      "    \n",
      "    Variance components are uncorrelated with each other, and with the\n",
      "    standard random effects.  Each variance component has mean zero, and\n",
      "    all realizations of a given variance component have the same variance\n",
      "    parameter.  The number of realized variance components per variance\n",
      "    parameter can differ across the groups.\n",
      "    \n",
      "    The primary reference for the implementation details is:\n",
      "    \n",
      "    MJ Lindstrom, DM Bates (1988).  \"Newton Raphson and EM algorithms for\n",
      "    linear mixed effects models for repeated measures data\".  Journal of\n",
      "    the American Statistical Association. Volume 83, Issue 404, pages\n",
      "    1014-1022.\n",
      "    \n",
      "    See also this more recent document:\n",
      "    \n",
      "    http://econ.ucsb.edu/~doug/245a/Papers/Mixed%20Effects%20Implement.pdf\n",
      "    \n",
      "    All the likelihood, gradient, and Hessian calculations closely follow\n",
      "    Lindstrom and Bates 1988, adapted to support variance components.\n",
      "    \n",
      "    The following two documents are written more from the perspective of\n",
      "    users:\n",
      "    \n",
      "    http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf\n",
      "    \n",
      "    http://lme4.r-forge.r-project.org/slides/2009-07-07-Rennes/3Longitudinal-4.pdf\n",
      "    \n",
      "    Notation:\n",
      "    \n",
      "    * `cov_re` is the random effects covariance matrix (referred to above\n",
      "      as Psi) and `scale` is the (scalar) error variance.  For a single\n",
      "      group, the marginal covariance matrix of endog given exog is scale*I\n",
      "      + Z * cov_re * Z', where Z is the design matrix for the random\n",
      "      effects in one group.\n",
      "    \n",
      "    * `vcomp` is a vector of variance parameters.  The length of `vcomp`\n",
      "      is determined by the number of keys in either the `exog_vc` argument\n",
      "      to ``MixedLM``, or the `vc_formula` argument when using formulas to\n",
      "      fit a model.\n",
      "    \n",
      "    Notes:\n",
      "    \n",
      "    1. Three different parameterizations are used in different places.\n",
      "    The regression slopes (usually called `fe_params`) are identical in\n",
      "    all three parameterizations, but the variance parameters differ.  The\n",
      "    parameterizations are:\n",
      "    \n",
      "    * The \"user parameterization\" in which cov(endog) = scale*I + Z *\n",
      "      cov_re * Z', as described above.  This is the main parameterization\n",
      "      visible to the user.\n",
      "    \n",
      "    * The \"profile parameterization\" in which cov(endog) = I +\n",
      "      Z * cov_re1 * Z'.  This is the parameterization of the profile\n",
      "      likelihood that is maximized to produce parameter estimates.\n",
      "      (see Lindstrom and Bates for details).  The \"user\" cov_re is\n",
      "      equal to the \"profile\" cov_re1 times the scale.\n",
      "    \n",
      "    * The \"square root parameterization\" in which we work with the Cholesky\n",
      "      factor of cov_re1 instead of cov_re directly.  This is hidden from the\n",
      "      user.\n",
      "    \n",
      "    All three parameterizations can be packed into a vector by\n",
      "    (optionally) concatenating `fe_params` together with the lower\n",
      "    triangle or Cholesky square root of the dependence structure, followed\n",
      "    by the variance parameters for the variance components.  The are\n",
      "    stored as square roots if (and only if) the random effects covariance\n",
      "    matrix is stored as its Cholesky factor.  Note that when unpacking, it\n",
      "    is important to either square or reflect the dependence structure\n",
      "    depending on which parameterization is being used.\n",
      "    \n",
      "    Two score methods are implemented.  One takes the score with respect\n",
      "    to the elements of the random effects covariance matrix (used for\n",
      "    inference once the MLE is reached), and the other takes the score with\n",
      "    respect to the parameters of the Cholesky square root of the random\n",
      "    effects covariance matrix (used for optimization).\n",
      "    \n",
      "    The numerical optimization uses GLS to avoid explicitly optimizing\n",
      "    over the fixed effects parameters.  The likelihood that is optimized\n",
      "    is profiled over both the scale parameter (a scalar) and the fixed\n",
      "    effects parameters (if any).  As a result of this profiling, it is\n",
      "    difficult and unnecessary to calculate the Hessian of the profiled log\n",
      "    likelihood function, so that calculation is not implemented here.\n",
      "    Therefore, optimization methods requiring the Hessian matrix such as\n",
      "    the Newton-Raphson algorithm cannot be used for model fitting.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        MixedLMParams\n",
      "        VCSpec\n",
      "    statsmodels.base.model.LikelihoodModel(statsmodels.base.model.Model)\n",
      "        MixedLM\n",
      "    statsmodels.base.model.LikelihoodModelResults(statsmodels.base.model.Results)\n",
      "        MixedLMResults(statsmodels.base.model.LikelihoodModelResults, statsmodels.base.model.ResultMixin)\n",
      "    statsmodels.base.model.LikelihoodResultsWrapper(statsmodels.base.wrapper.ResultsWrapper)\n",
      "        MixedLMResultsWrapper\n",
      "    statsmodels.base.model.ResultMixin(builtins.object)\n",
      "        MixedLMResults(statsmodels.base.model.LikelihoodModelResults, statsmodels.base.model.ResultMixin)\n",
      "    \n",
      "    class MixedLM(statsmodels.base.model.LikelihoodModel)\n",
      "     |  MixedLM(endog, exog, groups, exog_re=None, exog_vc=None, use_sqrt=True, missing='none', **kwargs)\n",
      "     |  \n",
      "     |  Linear Mixed Effects Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : 1d array_like\n",
      "     |      The dependent variable\n",
      "     |  exog : 2d array_like\n",
      "     |      A matrix of covariates used to determine the\n",
      "     |      mean structure (the \"fixed effects\" covariates).\n",
      "     |  groups : 1d array_like\n",
      "     |      A vector of labels determining the groups -- data from\n",
      "     |      different groups are independent\n",
      "     |  exog_re : 2d array_like\n",
      "     |      A matrix of covariates used to determine the variance and\n",
      "     |      covariance structure (the \"random effects\" covariates).  If\n",
      "     |      None, defaults to a random intercept for each group.\n",
      "     |  exog_vc : VCSpec instance or dict-like (deprecated)\n",
      "     |      A VCSPec instance defines the structure of the variance\n",
      "     |      components in the model.  Alternatively, see notes below\n",
      "     |      for a dictionary-based format.  The dictionary format is\n",
      "     |      deprecated and may be removed at some point in the future.\n",
      "     |  use_sqrt : bool\n",
      "     |      If True, optimization is carried out using the lower\n",
      "     |      triangle of the square root of the random effects\n",
      "     |      covariance matrix, otherwise it is carried out using the\n",
      "     |      lower triangle of the random effects covariance matrix.\n",
      "     |  missing : str\n",
      "     |      The approach to missing data handling\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  If `exog_vc` is not a `VCSpec` instance, then it must be a\n",
      "     |  dictionary of dictionaries.  Specifically, `exog_vc[a][g]` is a\n",
      "     |  matrix whose columns are linearly combined using independent\n",
      "     |  random coefficients.  This random term then contributes to the\n",
      "     |  variance structure of the data for group `g`.  The random\n",
      "     |  coefficients all have mean zero, and have the same variance.  The\n",
      "     |  matrix must be `m x k`, where `m` is the number of observations in\n",
      "     |  group `g`.  The number of columns may differ among the top-level\n",
      "     |  groups.\n",
      "     |  \n",
      "     |  The covariates in `exog`, `exog_re` and `exog_vc` may (but need\n",
      "     |  not) partially or wholly overlap.\n",
      "     |  \n",
      "     |  `use_sqrt` should almost always be set to True.  The main use case\n",
      "     |  for use_sqrt=False is when complicated patterns of fixed values in\n",
      "     |  the covariance structure are set (using the `free` argument to\n",
      "     |  `fit`) that cannot be expressed in terms of the Cholesky factor L.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  A basic mixed model with fixed effects for the columns of\n",
      "     |  ``exog`` and a random intercept for each distinct value of\n",
      "     |  ``group``:\n",
      "     |  \n",
      "     |  >>> model = sm.MixedLM(endog, exog, groups)\n",
      "     |  >>> result = model.fit()\n",
      "     |  \n",
      "     |  A mixed model with fixed effects for the columns of ``exog`` and\n",
      "     |  correlated random coefficients for the columns of ``exog_re``:\n",
      "     |  \n",
      "     |  >>> model = sm.MixedLM(endog, exog, groups, exog_re=exog_re)\n",
      "     |  >>> result = model.fit()\n",
      "     |  \n",
      "     |  A mixed model with fixed effects for the columns of ``exog`` and\n",
      "     |  independent random coefficients for the columns of ``exog_re``:\n",
      "     |  \n",
      "     |  >>> free = MixedLMParams.from_components(\n",
      "     |                   fe_params=np.ones(exog.shape[1]),\n",
      "     |                   cov_re=np.eye(exog_re.shape[1]))\n",
      "     |  >>> model = sm.MixedLM(endog, exog, groups, exog_re=exog_re)\n",
      "     |  >>> result = model.fit(free=free)\n",
      "     |  \n",
      "     |  A different way to specify independent random coefficients for the\n",
      "     |  columns of ``exog_re``.  In this example ``groups`` must be a\n",
      "     |  Pandas Series with compatible indexing with ``exog_re``, and\n",
      "     |  ``exog_re`` has two columns.\n",
      "     |  \n",
      "     |  >>> g = pd.groupby(groups, by=groups).groups\n",
      "     |  >>> vc = {}\n",
      "     |  >>> vc['1'] = {k : exog_re.loc[g[k], 0] for k in g}\n",
      "     |  >>> vc['2'] = {k : exog_re.loc[g[k], 1] for k in g}\n",
      "     |  >>> model = sm.MixedLM(endog, exog, groups, vcomp=vc)\n",
      "     |  >>> result = model.fit()\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MixedLM\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, groups, exog_re=None, exog_vc=None, use_sqrt=True, missing='none', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, reml=True, niter_sa=0, do_cg=True, fe_pen=None, cov_pen=None, free=None, full_output=False, method=None, **fit_kwargs)\n",
      "     |      Fit a linear mixed model to the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like or MixedLMParams\n",
      "     |          Starting values for the profile log-likelihood.  If not a\n",
      "     |          `MixedLMParams` instance, this should be an array\n",
      "     |          containing the packed parameters for the profile\n",
      "     |          log-likelihood, including the fixed effects\n",
      "     |          parameters.\n",
      "     |      reml : bool\n",
      "     |          If true, fit according to the REML likelihood, else\n",
      "     |          fit the standard likelihood using ML.\n",
      "     |      niter_sa : int\n",
      "     |          Currently this argument is ignored and has no effect\n",
      "     |          on the results.\n",
      "     |      cov_pen : CovariancePenalty object\n",
      "     |          A penalty for the random effects covariance matrix\n",
      "     |      do_cg : bool, defaults to True\n",
      "     |          If False, the optimization is skipped and a results\n",
      "     |          object at the given (or default) starting values is\n",
      "     |          returned.\n",
      "     |      fe_pen : Penalty object\n",
      "     |          A penalty on the fixed effects\n",
      "     |      free : MixedLMParams object\n",
      "     |          If not `None`, this is a mask that allows parameters to be\n",
      "     |          held fixed at specified values.  A 1 indicates that the\n",
      "     |          corresponding parameter is estimated, a 0 indicates that\n",
      "     |          it is fixed at its starting value.  Setting the `cov_re`\n",
      "     |          component to the identity matrix fits a model with\n",
      "     |          independent random effects.  Note that some optimization\n",
      "     |          methods do not respect this constraint (bfgs and lbfgs both\n",
      "     |          work).\n",
      "     |      full_output : bool\n",
      "     |          If true, attach iteration history to results\n",
      "     |      method : str\n",
      "     |          Optimization method.  Can be a scipy.optimize method name,\n",
      "     |          or a list of such names to be tried in sequence.\n",
      "     |      **fit_kwargs\n",
      "     |          Additional keyword arguments passed to fit.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A MixedLMResults instance.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', alpha=0, ceps=0.0001, ptol=1e-06, maxit=200, **fit_kwargs)\n",
      "     |      Fit a model in which the fixed effects parameters are\n",
      "     |      penalized.  The dependence parameters are held fixed at their\n",
      "     |      estimated values in the unpenalized model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str of Penalty object\n",
      "     |          Method for regularization.  If a string, must be 'l1'.\n",
      "     |      alpha : array_like\n",
      "     |          Scalar or vector of penalty weights.  If a scalar, the\n",
      "     |          same weight is applied to all coefficients; if a vector,\n",
      "     |          it contains a weight for each coefficient.  If method is a\n",
      "     |          Penalty object, the weights are scaled by alpha.  For L1\n",
      "     |          regularization, the weights are used directly.\n",
      "     |      ceps : positive real scalar\n",
      "     |          Fixed effects parameters smaller than this value\n",
      "     |          in magnitude are treated as being zero.\n",
      "     |      ptol : positive real scalar\n",
      "     |          Convergence occurs when the sup norm difference\n",
      "     |          between successive values of `fe_params` is less than\n",
      "     |          `ptol`.\n",
      "     |      maxit : int\n",
      "     |          The maximum number of iterations.\n",
      "     |      **fit_kwargs\n",
      "     |          Additional keyword arguments passed to fit.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A MixedLMResults instance containing the results.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The covariance structure is not updated as the fixed effects\n",
      "     |      parameters are varied.\n",
      "     |      \n",
      "     |      The algorithm used here for L1 regularization is a\"shooting\"\n",
      "     |      or cyclic coordinate descent algorithm.\n",
      "     |      \n",
      "     |      If method is 'l1', then `fe_pen` and `cov_pen` are used to\n",
      "     |      obtain the covariance structure, but are ignored during the\n",
      "     |      L1-penalized fitting.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Friedman, J. H., Hastie, T. and Tibshirani, R. Regularized\n",
      "     |      Paths for Generalized Linear Models via Coordinate\n",
      "     |      Descent. Journal of Statistical Software, 33(1) (2008)\n",
      "     |      http://www.jstatsoft.org/v33/i01/paper\n",
      "     |      \n",
      "     |      http://statweb.stanford.edu/~tibs/stat315a/Supplements/fuse.pdf\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale, exog)\n",
      "     |  \n",
      "     |  get_fe_params(self, cov_re, vcomp, tol=1e-10)\n",
      "     |      Use GLS to update the fixed effects parameter estimates.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cov_re : array_like (2d)\n",
      "     |          The covariance matrix of the random effects.\n",
      "     |      vcomp : array_like (1d)\n",
      "     |          The variance components.\n",
      "     |      tol : float\n",
      "     |          A tolerance parameter to determine when covariances\n",
      "     |          are singular.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : ndarray\n",
      "     |          The GLS estimates of the fixed effects parameters.\n",
      "     |      singular : bool\n",
      "     |          True if the covariance is singular\n",
      "     |  \n",
      "     |  get_scale(self, fe_params, cov_re, vcomp)\n",
      "     |      Returns the estimated error variance based on given estimates\n",
      "     |      of the slopes and random effects covariance matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fe_params : array_like\n",
      "     |          The regression slope estimates\n",
      "     |      cov_re : 2d array_like\n",
      "     |          Estimate of the random effects covariance matrix\n",
      "     |      vcomp : array_like\n",
      "     |          Estimate of the variance components\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scale : float\n",
      "     |          The estimated error variance.\n",
      "     |  \n",
      "     |  group_list(self, array)\n",
      "     |      Returns `array` split into subarrays corresponding to the\n",
      "     |      grouping structure.\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Returns the model's Hessian matrix.\n",
      "     |      \n",
      "     |      Calculates the Hessian matrix for the linear mixed effects\n",
      "     |      model with respect to the parameterization in which the\n",
      "     |      covariance matrix is represented directly (without square-root\n",
      "     |      transformation).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : MixedLMParams or array_like\n",
      "     |          The model parameters at which the Hessian is calculated.\n",
      "     |          If array-like, must contain the packed parameters in a\n",
      "     |          form that is compatible with this model instance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : 2d ndarray\n",
      "     |          The Hessian matrix, evaluated at `params`.\n",
      "     |      sing : boolean\n",
      "     |          If True, the covariance matrix is singular and a\n",
      "     |          pseudo-inverse is returned.\n",
      "     |  \n",
      "     |  loglike(self, params, profile_fe=True)\n",
      "     |      Evaluate the (profile) log-likelihood of the linear mixed\n",
      "     |      effects model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : MixedLMParams, or array_like.\n",
      "     |          The parameter value.  If array-like, must be a packed\n",
      "     |          parameter vector containing only the covariance\n",
      "     |          parameters.\n",
      "     |      profile_fe : bool\n",
      "     |          If True, replace the provided value of `fe_params` with\n",
      "     |          the GLS estimates.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The log-likelihood value at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The scale parameter `scale` is always profiled out of the\n",
      "     |      log-likelihood.  In addition, if `profile_fe` is true the\n",
      "     |      fixed effects parameters are also profiled out.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None)\n",
      "     |      Return predicted values from a design matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters of a mixed linear model.  Can be either a\n",
      "     |          MixedLMParams instance, or a vector containing the packed\n",
      "     |          model parameters in which the fixed effects parameters are\n",
      "     |          at the beginning of the vector, or a vector containing\n",
      "     |          only the fixed effects parameters.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data for the fixed effects. Model exog\n",
      "     |          is used if None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An array of fitted values.  Note that these predicted values\n",
      "     |      only reflect the fixed effects mean structure of the model.\n",
      "     |  \n",
      "     |  score(self, params, profile_fe=True)\n",
      "     |      Returns the score vector of the profile log-likelihood.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The score vector that is returned is computed with respect to\n",
      "     |      the parameterization defined by this model instance's\n",
      "     |      `use_sqrt` attribute.\n",
      "     |  \n",
      "     |  score_full(self, params, calc_fe)\n",
      "     |      Returns the score with respect to untransformed parameters.\n",
      "     |      \n",
      "     |      Calculates the score vector for the profiled log-likelihood of\n",
      "     |      the mixed effects model with respect to the parameterization\n",
      "     |      in which the random effects covariance matrix is represented\n",
      "     |      in its full form (not using the Cholesky factor).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : MixedLMParams or array_like\n",
      "     |          The parameter at which the score function is evaluated.\n",
      "     |          If array-like, must contain the packed random effects\n",
      "     |          parameters (cov_re and vcomp) without fe_params.\n",
      "     |      calc_fe : bool\n",
      "     |          If True, calculate the score vector for the fixed effects\n",
      "     |          parameters.  If False, this vector is not calculated, and\n",
      "     |          a vector of zeros is returned in its place.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_fe : array_like\n",
      "     |          The score vector with respect to the fixed effects\n",
      "     |          parameters.\n",
      "     |      score_re : array_like\n",
      "     |          The score vector with respect to the random effects\n",
      "     |          parameters (excluding variance components parameters).\n",
      "     |      score_vc : array_like\n",
      "     |          The score vector with respect to variance components\n",
      "     |          parameters.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `score_re` is taken with respect to the parameterization in\n",
      "     |      which `cov_re` is represented through its lower triangle\n",
      "     |      (without taking the Cholesky square root).\n",
      "     |  \n",
      "     |  score_sqrt(self, params, calc_fe=True)\n",
      "     |      Returns the score with respect to transformed parameters.\n",
      "     |      \n",
      "     |      Calculates the score vector with respect to the\n",
      "     |      parameterization in which the random effects covariance matrix\n",
      "     |      is represented through its Cholesky square root.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : MixedLMParams or array_like\n",
      "     |          The model parameters.  If array-like must contain packed\n",
      "     |          parameters that are compatible with this model instance.\n",
      "     |      calc_fe : bool\n",
      "     |          If True, calculate the score vector for the fixed effects\n",
      "     |          parameters.  If False, this vector is not calculated, and\n",
      "     |          a vector of zeros is returned in its place.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_fe : array_like\n",
      "     |          The score vector with respect to the fixed effects\n",
      "     |          parameters.\n",
      "     |      score_re : array_like\n",
      "     |          The score vector with respect to the random effects\n",
      "     |          parameters (excluding variance components parameters).\n",
      "     |      score_vc : array_like\n",
      "     |          The score vector with respect to variance components\n",
      "     |          parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula, data, re_formula=None, vc_formula=None, subset=None, use_sparse=False, missing='none', *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      re_formula : str\n",
      "     |          A one-sided formula defining the variance structure of the\n",
      "     |          model.  The default gives a random intercept for each\n",
      "     |          group.\n",
      "     |      vc_formula : dict-like\n",
      "     |          Formulas describing variance components.  `vc_formula[vc]` is\n",
      "     |          the formula for the component with variance parameter named\n",
      "     |          `vc`.  The formula is processed into a matrix, and the columns\n",
      "     |          of this matrix are linearly combined with independent random\n",
      "     |          coefficients having mean zero and a common variance.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index\n",
      "     |          values that indicate the subset of df to use in the\n",
      "     |          model. Assumes df is a `pandas.DataFrame`\n",
      "     |      missing : str\n",
      "     |          Either 'none' or 'drop'\n",
      "     |      args : extra arguments\n",
      "     |          These are passed to the model\n",
      "     |      kwargs : extra keyword arguments\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : Model instance\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `data` must define __getitem__ with the keys in the formula\n",
      "     |      terms args and kwargs are passed on to the model\n",
      "     |      instantiation. E.g., a numpy structured or rec array, a\n",
      "     |      dictionary, or a pandas DataFrame.\n",
      "     |      \n",
      "     |      If the variance component is intended to produce random\n",
      "     |      intercepts for disjoint subsets of a group, specified by\n",
      "     |      string labels or a categorical data value, always use '0 +' in\n",
      "     |      the formula so that no overall intercept is included.\n",
      "     |      \n",
      "     |      If the variance components specify random slopes and you do\n",
      "     |      not also want a random group-level intercept in the model,\n",
      "     |      then use '0 +' in the formula to exclude the intercept.\n",
      "     |      \n",
      "     |      The variance components formulas are processed separately for\n",
      "     |      each group.  If a variable is categorical the results will not\n",
      "     |      be affected by whether the group labels are distinct or\n",
      "     |      re-used over the top-level groups.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Suppose we have data from an educational study with students\n",
      "     |      nested in classrooms nested in schools.  The students take a\n",
      "     |      test, and we want to relate the test scores to the students'\n",
      "     |      ages, while accounting for the effects of classrooms and\n",
      "     |      schools.  The school will be the top-level group, and the\n",
      "     |      classroom is a nested group that is specified as a variance\n",
      "     |      component.  Note that the schools may have different number of\n",
      "     |      classrooms, and the classroom labels may (but need not be)\n",
      "     |      different across the schools.\n",
      "     |      \n",
      "     |      >>> vc = {'classroom': '0 + C(classroom)'}\n",
      "     |      >>> MixedLM.from_formula('test_score ~ age', vc_formula=vc,                                   re_formula='1', groups='school', data=data)\n",
      "     |      \n",
      "     |      Now suppose we also have a previous test score called\n",
      "     |      'pretest'.  If we want the relationship between pretest\n",
      "     |      scores and the current test to vary by classroom, we can\n",
      "     |      specify a random slope for the pretest score\n",
      "     |      \n",
      "     |      >>> vc = {'classroom': '0 + C(classroom)', 'pretest': '0 + pretest'}\n",
      "     |      >>> MixedLM.from_formula('test_score ~ age + pretest', vc_formula=vc,                                   re_formula='1', groups='school', data=data)\n",
      "     |      \n",
      "     |      The following model is almost equivalent to the previous one,\n",
      "     |      but here the classroom random intercept and pretest slope may\n",
      "     |      be correlated.\n",
      "     |      \n",
      "     |      >>> vc = {'classroom': '0 + C(classroom)'}\n",
      "     |      >>> MixedLM.from_formula('test_score ~ age + pretest', vc_formula=vc,                                   re_formula='1 + pretest', groups='school',                                   data=data)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MixedLMParams(builtins.object)\n",
      "     |  MixedLMParams(k_fe, k_re, k_vc)\n",
      "     |  \n",
      "     |  This class represents a parameter state for a mixed linear model.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  k_fe : int\n",
      "     |      The number of covariates with fixed effects.\n",
      "     |  k_re : int\n",
      "     |      The number of covariates with random coefficients (excluding\n",
      "     |      variance components).\n",
      "     |  k_vc : int\n",
      "     |      The number of variance components parameters.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This object represents the parameter state for the model in which\n",
      "     |  the scale parameter has been profiled out.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, k_fe, k_re, k_vc)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Returns a copy of the object.\n",
      "     |  \n",
      "     |  get_packed(self, use_sqrt, has_fe=False)\n",
      "     |      Return the model parameters packed into a single vector.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      use_sqrt : bool\n",
      "     |          If True, the Cholesky square root of `cov_re` is\n",
      "     |          included in the packed result.  Otherwise the\n",
      "     |          lower triangle of `cov_re` is included.\n",
      "     |      has_fe : bool\n",
      "     |          If True, the fixed effects parameters are included\n",
      "     |          in the packed result, otherwise they are omitted.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_components(fe_params=None, cov_re=None, cov_re_sqrt=None, vcomp=None)\n",
      "     |      Create a MixedLMParams object from each parameter component.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fe_params : array_like\n",
      "     |          The fixed effects parameter (a 1-dimensional array).  If\n",
      "     |          None, there are no fixed effects.\n",
      "     |      cov_re : array_like\n",
      "     |          The random effects covariance matrix (a square, symmetric\n",
      "     |          2-dimensional array).\n",
      "     |      cov_re_sqrt : array_like\n",
      "     |          The Cholesky (lower triangular) square root of the random\n",
      "     |          effects covariance matrix.\n",
      "     |      vcomp : array_like\n",
      "     |          The variance component parameters.  If None, there are no\n",
      "     |          variance components.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A MixedLMParams object.\n",
      "     |  \n",
      "     |  from_packed(params, k_fe, k_re, use_sqrt, has_fe)\n",
      "     |      Create a MixedLMParams object from packed parameter vector.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The mode parameters packed into a single vector.\n",
      "     |      k_fe : int\n",
      "     |          The number of covariates with fixed effects\n",
      "     |      k_re : int\n",
      "     |          The number of covariates with random effects (excluding\n",
      "     |          variance components).\n",
      "     |      use_sqrt : bool\n",
      "     |          If True, the random effects covariance matrix is provided\n",
      "     |          as its Cholesky factor, otherwise the lower triangle of\n",
      "     |          the covariance matrix is stored.\n",
      "     |      has_fe : bool\n",
      "     |          If True, `params` contains fixed effects parameters.\n",
      "     |          Otherwise, the fixed effects parameters are set to zero.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A MixedLMParams object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MixedLMResults(statsmodels.base.model.LikelihoodModelResults, statsmodels.base.model.ResultMixin)\n",
      "     |  MixedLMResults(model, params, cov_params)\n",
      "     |  \n",
      "     |  Class to contain results of fitting a linear mixed effects model.\n",
      "     |  \n",
      "     |  MixedLMResults inherits from statsmodels.LikelihoodModelResults\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  See statsmodels.LikelihoodModelResults\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  model : class instance\n",
      "     |      Pointer to MixedLM model instance that called fit.\n",
      "     |  normalized_cov_params : ndarray\n",
      "     |      The sampling covariance matrix of the estimates\n",
      "     |  params : ndarray\n",
      "     |      A packed parameter vector for the profile parameterization.\n",
      "     |      The first `k_fe` elements are the estimated fixed effects\n",
      "     |      coefficients.  The remaining elements are the estimated\n",
      "     |      variance parameters.  The variance parameters are all divided\n",
      "     |      by `scale` and are not the variance parameters shown\n",
      "     |      in the summary.\n",
      "     |  fe_params : ndarray\n",
      "     |      The fitted fixed-effects coefficients\n",
      "     |  cov_re : ndarray\n",
      "     |      The fitted random-effects covariance matrix\n",
      "     |  bse_fe : ndarray\n",
      "     |      The standard errors of the fitted fixed effects coefficients\n",
      "     |  bse_re : ndarray\n",
      "     |      The standard errors of the fitted random effects covariance\n",
      "     |      matrix and variance components.  The first `k_re * (k_re + 1)`\n",
      "     |      parameters are the standard errors for the lower triangle of\n",
      "     |      `cov_re`, the remaining elements are the standard errors for\n",
      "     |      the variance components.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.LikelihoodModelResults\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MixedLMResults\n",
      "     |      statsmodels.base.model.LikelihoodModelResults\n",
      "     |      statsmodels.base.model.Results\n",
      "     |      statsmodels.base.model.ResultMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, model, params, cov_params)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  profile_re(self, re_ix, vtype, num_low=5, dist_low=1.0, num_high=5, dist_high=1.0, **fit_kwargs)\n",
      "     |      Profile-likelihood inference for variance parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      re_ix : int\n",
      "     |          If vtype is `re`, this value is the index of the variance\n",
      "     |          parameter for which to construct a profile likelihood.  If\n",
      "     |          `vtype` is 'vc' then `re_ix` is the name of the variance\n",
      "     |          parameter to be profiled.\n",
      "     |      vtype : str\n",
      "     |          Either 're' or 'vc', depending on whether the profile\n",
      "     |          analysis is for a random effect or a variance component.\n",
      "     |      num_low : int\n",
      "     |          The number of points at which to calculate the likelihood\n",
      "     |          below the MLE of the parameter of interest.\n",
      "     |      dist_low : float\n",
      "     |          The distance below the MLE of the parameter of interest to\n",
      "     |          begin calculating points on the profile likelihood.\n",
      "     |      num_high : int\n",
      "     |          The number of points at which to calculate the likelihood\n",
      "     |          above the MLE of the parameter of interest.\n",
      "     |      dist_high : float\n",
      "     |          The distance above the MLE of the parameter of interest to\n",
      "     |          begin calculating points on the profile likelihood.\n",
      "     |      **fit_kwargs\n",
      "     |          Additional keyword arguments passed to fit.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An array with two columns.  The first column contains the\n",
      "     |      values to which the parameter of interest is constrained.  The\n",
      "     |      second column contains the corresponding likelihood values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only variance parameters can be profiled.\n",
      "     |  \n",
      "     |  summary(self, yname=None, xname_fe=None, xname_re=None, title=None, alpha=0.05)\n",
      "     |      Summarize the mixed model regression results.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      yname : str, optional\n",
      "     |          Default is `y`\n",
      "     |      xname_fe : list[str], optional\n",
      "     |          Fixed effects covariate names\n",
      "     |      xname_re : list[str], optional\n",
      "     |          Random effects covariate names\n",
      "     |      title : str, optional\n",
      "     |          Title for the top table. If not None, then this replaces\n",
      "     |          the default title\n",
      "     |      alpha : float\n",
      "     |          significance level for the confidence intervals\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      smry : Summary instance\n",
      "     |          this holds the summary tables and text, which can be\n",
      "     |          printed or converted to various output formats.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.iolib.summary2.Summary : class to hold summary results\n",
      "     |  \n",
      "     |  t_test(self, r_matrix, use_t=None)\n",
      "     |      Compute a t-test for a each linear hypothesis of the form Rb = q\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array_like\n",
      "     |          If an array is given, a p x k 2d array or length k 1d\n",
      "     |          array specifying the linear restrictions. It is assumed\n",
      "     |          that the linear combination is equal to zero.\n",
      "     |      scale : float, optional\n",
      "     |          An optional `scale` to use.  Default is the scale specified\n",
      "     |          by the model fit.\n",
      "     |      use_t : bool, optional\n",
      "     |          If use_t is None, then the default of the model is used.\n",
      "     |          If use_t is True, then the p-values are based on the t\n",
      "     |          distribution.\n",
      "     |          If use_t is False, then the p-values are based on the normal\n",
      "     |          distribution.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res : ContrastResults instance\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |          The available results have the same elements as the parameter table\n",
      "     |          in `summary()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  aic\n",
      "     |      Akaike information criterion\n",
      "     |  \n",
      "     |  bic\n",
      "     |      Bayesian information criterion\n",
      "     |  \n",
      "     |  bse_fe\n",
      "     |      Returns the standard errors of the fixed effect regression\n",
      "     |      coefficients.\n",
      "     |  \n",
      "     |  bse_re\n",
      "     |      Returns the standard errors of the variance parameters.\n",
      "     |      \n",
      "     |      The first `k_re x (k_re + 1)` elements of the returned array\n",
      "     |      are the standard errors of the lower triangle of `cov_re`.\n",
      "     |      The remaining elements are the standard errors of the variance\n",
      "     |      components.\n",
      "     |      \n",
      "     |      Note that the sampling distribution of variance parameters is\n",
      "     |      strongly skewed unless the sample size is large, so these\n",
      "     |      standard errors may not give meaningful confidence intervals\n",
      "     |      or p-values if used in the usual way.\n",
      "     |  \n",
      "     |  fittedvalues\n",
      "     |      Returns the fitted values for the model.\n",
      "     |      \n",
      "     |      The fitted values reflect the mean structure specified by the\n",
      "     |      fixed effects and the predicted random effects.\n",
      "     |  \n",
      "     |  llf\n",
      "     |  \n",
      "     |  random_effects\n",
      "     |      The conditional means of random effects given the data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      random_effects : dict\n",
      "     |          A dictionary mapping the distinct `group` values to the\n",
      "     |          conditional means of the random effects for the group\n",
      "     |          given the data.\n",
      "     |  \n",
      "     |  random_effects_cov\n",
      "     |      Returns the conditional covariance matrix of the random\n",
      "     |      effects for each group given the data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      random_effects_cov : dict\n",
      "     |          A dictionary mapping the distinct values of the `group`\n",
      "     |          variable to the conditional covariance matrix of the\n",
      "     |          random effects given the data.\n",
      "     |  \n",
      "     |  resid\n",
      "     |      Returns the residuals for the model.\n",
      "     |      \n",
      "     |      The residuals reflect the mean structure specified by the\n",
      "     |      fixed effects and the predicted random effects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModelResults:\n",
      "     |  \n",
      "     |  conf_int(self, alpha=0.05, cols=None)\n",
      "     |      Construct confidence interval for the fitted parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : float, optional\n",
      "     |          The significance level for the confidence interval. The default\n",
      "     |          `alpha` = .05 returns a 95% confidence interval.\n",
      "     |      cols : array_like, optional\n",
      "     |          Specifies which confidence intervals to return.\n",
      "     |      \n",
      "     |      .. deprecated: 0.13\n",
      "     |      \n",
      "     |         cols is deprecated and will be removed after 0.14 is released.\n",
      "     |         cols only works when inputs are NumPy arrays and will fail\n",
      "     |         when using pandas Series or DataFrames as input. You can\n",
      "     |         subset the confidence intervals using slices.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          Each row contains [lower, upper] limits of the confidence interval\n",
      "     |          for the corresponding parameter. The first column contains all\n",
      "     |          lower, the second column contains all upper limits.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The confidence interval is based on the standard normal distribution\n",
      "     |      if self.use_t is False. If self.use_t is True, then uses a Student's t\n",
      "     |      with self.df_resid_inference (or self.df_resid if df_resid_inference is\n",
      "     |      not defined) degrees of freedom.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> results.conf_int()\n",
      "     |      array([[-5496529.48322745, -1467987.78596704],\n",
      "     |             [    -177.02903529,      207.15277984],\n",
      "     |             [      -0.1115811 ,        0.03994274],\n",
      "     |             [      -3.12506664,       -0.91539297],\n",
      "     |             [      -1.5179487 ,       -0.54850503],\n",
      "     |             [      -0.56251721,        0.460309  ],\n",
      "     |             [     798.7875153 ,     2859.51541392]])\n",
      "     |      \n",
      "     |      >>> results.conf_int(cols=(2,3))\n",
      "     |      array([[-0.1115811 ,  0.03994274],\n",
      "     |             [-3.12506664, -0.91539297]])\n",
      "     |  \n",
      "     |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      Compute the variance/covariance matrix.\n",
      "     |      \n",
      "     |      The variance/covariance matrix can be of a linear contrast of the\n",
      "     |      estimated parameters or all params multiplied by scale which will\n",
      "     |      usually be an estimate of sigma^2.  Scale is assumed to be a scalar.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array_like\n",
      "     |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      "     |      column : array_like, optional\n",
      "     |          Must be used on its own.  Can be 0d or 1d see below.\n",
      "     |      scale : float, optional\n",
      "     |          Can be specified or not.  Default is None, which means that\n",
      "     |          the scale argument is taken from the model.\n",
      "     |      cov_p : ndarray, optional\n",
      "     |          The covariance of the parameters. If not provided, this value is\n",
      "     |          read from `self.normalized_cov_params` or\n",
      "     |          `self.cov_params_default`.\n",
      "     |      other : array_like, optional\n",
      "     |          Can be used when r_matrix is specified.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The covariance matrix of the parameter estimates or of linear\n",
      "     |          combination of parameter estimates. See Notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      (The below are assumed to be in matrix notation.)\n",
      "     |      \n",
      "     |      If no argument is specified returns the covariance matrix of a model\n",
      "     |      ``(scale)*(X.T X)^(-1)``\n",
      "     |      \n",
      "     |      If contrast is specified it pre and post-multiplies as follows\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      "     |      \n",
      "     |      If contrast and other are specified returns\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      "     |      \n",
      "     |      If column is specified returns\n",
      "     |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      "     |      \n",
      "     |      OR\n",
      "     |      \n",
      "     |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      "     |  \n",
      "     |  f_test(self, r_matrix, cov_p=None, invcov=None)\n",
      "     |      Compute the F-test for a joint linear hypothesis.\n",
      "     |      \n",
      "     |      This is a special case of `wald_test` that always uses the F\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : {array_like, str, tuple}\n",
      "     |          One of:\n",
      "     |      \n",
      "     |          - array : An r x k array where r is the number of restrictions to\n",
      "     |            test and k is the number of regressors. It is assumed\n",
      "     |            that the linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      "     |            either a scalar or a length k row vector.\n",
      "     |      \n",
      "     |      cov_p : array_like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      invcov : array_like, optional\n",
      "     |          A q x q array to specify an inverse covariance matrix based on a\n",
      "     |          restrictions matrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ContrastResults\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      t_test : Perform a single hypothesis test.\n",
      "     |      wald_test : Perform a Wald-test using a quadratic form.\n",
      "     |      statsmodels.stats.contrast.ContrastResults : Test results.\n",
      "     |      patsy.DesignInfo.linear_constraint : Specify a linear constraint.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      "     |      \n",
      "     |      r_matrix (pX pX.T) r_matrix.T\n",
      "     |      \n",
      "     |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      "     |      design matrix of the model. There can be problems in non-OLS models\n",
      "     |      where the rank of the covariance of the noise is not full.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> A = np.identity(len(results.params))\n",
      "     |      >>> A = A[1:,:]\n",
      "     |      \n",
      "     |      This tests that each coefficient is jointly statistically\n",
      "     |      significantly different from zero.\n",
      "     |      \n",
      "     |      >>> print(results.f_test(A))\n",
      "     |      <F test: F=array([[ 330.28533923]]), p=4.984030528700946e-10, df_denom=9, df_num=6>\n",
      "     |      \n",
      "     |      Compare this to\n",
      "     |      \n",
      "     |      >>> results.fvalue\n",
      "     |      330.2853392346658\n",
      "     |      >>> results.f_pvalue\n",
      "     |      4.98403096572e-10\n",
      "     |      \n",
      "     |      >>> B = np.array(([0,0,1,-1,0,0,0],[0,0,0,0,0,1,-1]))\n",
      "     |      \n",
      "     |      This tests that the coefficient on the 2nd and 3rd regressors are\n",
      "     |      equal and jointly that the coefficient on the 5th and 6th regressors\n",
      "     |      are equal.\n",
      "     |      \n",
      "     |      >>> print(results.f_test(B))\n",
      "     |      <F test: F=array([[ 9.74046187]]), p=0.005605288531708235, df_denom=9, df_num=2>\n",
      "     |      \n",
      "     |      Alternatively, you can specify the hypothesis tests using a string\n",
      "     |      \n",
      "     |      >>> from statsmodels.datasets import longley\n",
      "     |      >>> from statsmodels.formula.api import ols\n",
      "     |      >>> dta = longley.load_pandas().data\n",
      "     |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      "     |      >>> results = ols(formula, dta).fit()\n",
      "     |      >>> hypotheses = '(GNPDEFL = GNP), (UNEMP = 2), (YEAR/1829 = 1)'\n",
      "     |      >>> f_test = results.f_test(hypotheses)\n",
      "     |      >>> print(f_test)\n",
      "     |      <F test: F=array([[ 144.17976065]]), p=6.322026217355609e-08, df_denom=9, df_num=3>\n",
      "     |  \n",
      "     |  normalized_cov_params(self)\n",
      "     |      See specific model class docstring\n",
      "     |  \n",
      "     |  remove_data(self)\n",
      "     |      Remove data arrays, all nobs arrays from result and model.\n",
      "     |      \n",
      "     |      This reduces the size of the instance, so it can be pickled with less\n",
      "     |      memory. Currently tested for use with predict from an unpickled\n",
      "     |      results and model instance.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |         Since data and some intermediate results have been removed\n",
      "     |         calculating new statistics that require them will raise exceptions.\n",
      "     |         The exception will occur the first time an attribute is accessed\n",
      "     |         that has been set to None.\n",
      "     |      \n",
      "     |      Not fully tested for time series models, tsa, and might delete too much\n",
      "     |      for prediction or not all that would be possible.\n",
      "     |      \n",
      "     |      The lists of arrays to delete are maintained as attributes of\n",
      "     |      the result and model instance, except for cached values. These\n",
      "     |      lists could be changed before calling remove_data.\n",
      "     |      \n",
      "     |      The attributes to remove are named in:\n",
      "     |      \n",
      "     |      model._data_attr : arrays attached to both the model instance\n",
      "     |          and the results instance with the same attribute name.\n",
      "     |      \n",
      "     |      result._data_in_cache : arrays that may exist as values in\n",
      "     |          result._cache\n",
      "     |      \n",
      "     |      result._data_attr_model : arrays attached to the model\n",
      "     |          instance but not to the results instance\n",
      "     |  \n",
      "     |  save(self, fname, remove_data=False)\n",
      "     |      Save a pickle of this instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : {str, handle}\n",
      "     |          A string filename or a file handle.\n",
      "     |      remove_data : bool\n",
      "     |          If False (default), then the instance is pickled without changes.\n",
      "     |          If True, then all arrays with length nobs are set to None before\n",
      "     |          pickling. See the remove_data method.\n",
      "     |          In some cases not all arrays will be set to None.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If remove_data is true and the model result does not implement a\n",
      "     |      remove_data method then this will raise an exception.\n",
      "     |  \n",
      "     |  t_test_pairwise(self, term_name, method='hs', alpha=0.05, factor_labels=None)\n",
      "     |      Perform pairwise t_test with multiple testing corrected p-values.\n",
      "     |      \n",
      "     |      This uses the formula design_info encoding contrast matrix and should\n",
      "     |      work for all encodings of a main effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      term_name : str\n",
      "     |          The name of the term for which pairwise comparisons are computed.\n",
      "     |          Term names for categorical effects are created by patsy and\n",
      "     |          correspond to the main part of the exog names.\n",
      "     |      method : {str, list[str]}\n",
      "     |          The multiple testing p-value correction to apply. The default is\n",
      "     |          'hs'. See stats.multipletesting.\n",
      "     |      alpha : float\n",
      "     |          The significance level for multiple testing reject decision.\n",
      "     |      factor_labels : {list[str], None}\n",
      "     |          Labels for the factor levels used for pairwise labels. If not\n",
      "     |          provided, then the labels from the formula design_info are used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      MultiCompResult\n",
      "     |          The results are stored as attributes, the main attributes are the\n",
      "     |          following two. Other attributes are added for debugging purposes\n",
      "     |          or as background information.\n",
      "     |      \n",
      "     |          - result_frame : pandas DataFrame with t_test results and multiple\n",
      "     |            testing corrected p-values.\n",
      "     |          - contrasts : matrix of constraints of the null hypothesis in the\n",
      "     |            t_test.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Status: experimental. Currently only checked for treatment coding with\n",
      "     |      and without specified reference level.\n",
      "     |      \n",
      "     |      Currently there are no multiple testing corrected confidence intervals\n",
      "     |      available.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> res = ols(\"np.log(Days+1) ~ C(Weight) + C(Duration)\", data).fit()\n",
      "     |      >>> pw = res.t_test_pairwise(\"C(Weight)\")\n",
      "     |      >>> pw.result_frame\n",
      "     |               coef   std err         t         P>|t|  Conf. Int. Low\n",
      "     |      2-1  0.632315  0.230003  2.749157  8.028083e-03        0.171563\n",
      "     |      3-1  1.302555  0.230003  5.663201  5.331513e-07        0.841803\n",
      "     |      3-2  0.670240  0.230003  2.914044  5.119126e-03        0.209488\n",
      "     |           Conf. Int. Upp.  pvalue-hs reject-hs\n",
      "     |      2-1         1.093067   0.010212      True\n",
      "     |      3-1         1.763307   0.000002      True\n",
      "     |      3-2         1.130992   0.010212      True\n",
      "     |  \n",
      "     |  wald_test(self, r_matrix, cov_p=None, invcov=None, use_f=None, df_constraints=None, scalar=None)\n",
      "     |      Compute a Wald-test for a joint linear hypothesis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : {array_like, str, tuple}\n",
      "     |          One of:\n",
      "     |      \n",
      "     |          - array : An r x k array where r is the number of restrictions to\n",
      "     |            test and k is the number of regressors. It is assumed that the\n",
      "     |            linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      "     |            either a scalar or a length p row vector.\n",
      "     |      \n",
      "     |      cov_p : array_like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      invcov : array_like, optional\n",
      "     |          A q x q array to specify an inverse covariance matrix based on a\n",
      "     |          restrictions matrix.\n",
      "     |      use_f : bool\n",
      "     |          If True, then the F-distribution is used. If False, then the\n",
      "     |          asymptotic distribution, chisquare is used. If use_f is None, then\n",
      "     |          the F distribution is used if the model specifies that use_t is True.\n",
      "     |          The test statistic is proportionally adjusted for the distribution\n",
      "     |          by the number of constraints in the hypothesis.\n",
      "     |      df_constraints : int, optional\n",
      "     |          The number of constraints. If not provided the number of\n",
      "     |          constraints is determined from r_matrix.\n",
      "     |      scalar : bool, optional\n",
      "     |          Flag indicating whether the Wald test statistic should be returned\n",
      "     |          as a sclar float. The current behavior is to return an array.\n",
      "     |          This will switch to a scalar float after 0.14 is released. To\n",
      "     |          get the future behavior now, set scalar to True. To silence\n",
      "     |          the warning and retain the legacy behavior, set scalar to\n",
      "     |          False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ContrastResults\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      f_test : Perform an F tests on model parameters.\n",
      "     |      t_test : Perform a single hypothesis test.\n",
      "     |      statsmodels.stats.contrast.ContrastResults : Test results.\n",
      "     |      patsy.DesignInfo.linear_constraint : Specify a linear constraint.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      "     |      \n",
      "     |      r_matrix (pX pX.T) r_matrix.T\n",
      "     |      \n",
      "     |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      "     |      design matrix of the model. There can be problems in non-OLS models\n",
      "     |      where the rank of the covariance of the noise is not full.\n",
      "     |  \n",
      "     |  wald_test_terms(self, skip_single=False, extra_constraints=None, combine_terms=None, scalar=None)\n",
      "     |      Compute a sequence of Wald tests for terms over multiple columns.\n",
      "     |      \n",
      "     |      This computes joined Wald tests for the hypothesis that all\n",
      "     |      coefficients corresponding to a `term` are zero.\n",
      "     |      `Terms` are defined by the underlying formula or by string matching.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skip_single : bool\n",
      "     |          If true, then terms that consist only of a single column and,\n",
      "     |          therefore, refers only to a single parameter is skipped.\n",
      "     |          If false, then all terms are included.\n",
      "     |      extra_constraints : ndarray\n",
      "     |          Additional constraints to test. Note that this input has not been\n",
      "     |          tested.\n",
      "     |      combine_terms : {list[str], None}\n",
      "     |          Each string in this list is matched to the name of the terms or\n",
      "     |          the name of the exogenous variables. All columns whose name\n",
      "     |          includes that string are combined in one joint test.\n",
      "     |      scalar : bool, optional\n",
      "     |          Flag indicating whether the Wald test statistic should be returned\n",
      "     |          as a sclar float. The current behavior is to return an array.\n",
      "     |          This will switch to a scalar float after 0.14 is released. To\n",
      "     |          get the future behavior now, set scalar to True. To silence\n",
      "     |          the warning and retain the legacy behavior, set scalar to\n",
      "     |          False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      WaldTestResults\n",
      "     |          The result instance contains `table` which is a pandas DataFrame\n",
      "     |          with the test results: test statistic, degrees of freedom and\n",
      "     |          pvalues.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> res_ols = ols(\"np.log(Days+1) ~ C(Duration, Sum)*C(Weight, Sum)\", data).fit()\n",
      "     |      >>> res_ols.wald_test_terms()\n",
      "     |      <class 'statsmodels.stats.contrast.WaldTestResults'>\n",
      "     |                                                F                P>F  df constraint  df denom\n",
      "     |      Intercept                        279.754525  2.37985521351e-22              1        51\n",
      "     |      C(Duration, Sum)                   5.367071    0.0245738436636              1        51\n",
      "     |      C(Weight, Sum)                    12.432445  3.99943118767e-05              2        51\n",
      "     |      C(Duration, Sum):C(Weight, Sum)    0.176002      0.83912310946              2        51\n",
      "     |      \n",
      "     |      >>> res_poi = Poisson.from_formula(\"Days ~ C(Weight) * C(Duration)\",                                            data).fit(cov_type='HC0')\n",
      "     |      >>> wt = res_poi.wald_test_terms(skip_single=False,                                          combine_terms=['Duration', 'Weight'])\n",
      "     |      >>> print(wt)\n",
      "     |                                  chi2             P>chi2  df constraint\n",
      "     |      Intercept              15.695625  7.43960374424e-05              1\n",
      "     |      C(Weight)              16.132616  0.000313940174705              2\n",
      "     |      C(Duration)             1.009147     0.315107378931              1\n",
      "     |      C(Weight):C(Duration)   0.216694     0.897315972824              2\n",
      "     |      Duration               11.187849     0.010752286833              3\n",
      "     |      Weight                 30.263368  4.32586407145e-06              4\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.LikelihoodModelResults:\n",
      "     |  \n",
      "     |  load(fname) from builtins.type\n",
      "     |      Load a pickled results instance\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |         Loading pickled models is not secure against erroneous or\n",
      "     |         maliciously constructed data. Never unpickle data received from\n",
      "     |         an untrusted or unauthenticated source.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : {str, handle, pathlib.Path}\n",
      "     |          A string filename or a file handle.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          The unpickled results instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.LikelihoodModelResults:\n",
      "     |  \n",
      "     |  bse\n",
      "     |      The standard errors of the parameter estimates.\n",
      "     |  \n",
      "     |  pvalues\n",
      "     |      The two-tailed p values for the t-stats of the params.\n",
      "     |  \n",
      "     |  tvalues\n",
      "     |      Return the t-statistic for a given parameter estimate.\n",
      "     |  \n",
      "     |  use_t\n",
      "     |      Flag indicating to use the Student's distribution in inference.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Results:\n",
      "     |  \n",
      "     |  initialize(self, model, params, **kwargs)\n",
      "     |      Initialize (possibly re-initialize) a Results instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      model : Model\n",
      "     |          The model instance.\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |      **kwargs\n",
      "     |          Any additional keyword arguments required to initialize the model.\n",
      "     |  \n",
      "     |  predict(self, exog=None, transform=True, *args, **kwargs)\n",
      "     |      Call self.model.predict with self.params as the first argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array_like, optional\n",
      "     |          The values for which you want to predict. see Notes below.\n",
      "     |      transform : bool, optional\n",
      "     |          If the model was fit via a formula, do you want to pass\n",
      "     |          exog through the formula. Default is True. E.g., if you fit\n",
      "     |          a model y ~ log(x1) + log(x2), and transform is True, then\n",
      "     |          you can pass a data structure that contains x1 and x2 in\n",
      "     |          their original form. Otherwise, you'd need to log the data\n",
      "     |          first.\n",
      "     |      *args\n",
      "     |          Additional arguments to pass to the model, see the\n",
      "     |          predict method of the model for the details.\n",
      "     |      **kwargs\n",
      "     |          Additional keywords arguments to pass to the model, see the\n",
      "     |          predict method of the model for the details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          See self.model.predict.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The types of exog that are supported depends on whether a formula\n",
      "     |      was used in the specification of the model.\n",
      "     |      \n",
      "     |      If a formula was used, then exog is processed in the same way as\n",
      "     |      the original data. This transformation needs to have key access to the\n",
      "     |      same variable names, and can be a pandas DataFrame or a dict like\n",
      "     |      object that contains numpy arrays.\n",
      "     |      \n",
      "     |      If no formula was used, then the provided exog needs to have the\n",
      "     |      same number of columns as the original exog in the model. No\n",
      "     |      transformation of the data is performed except converting it to\n",
      "     |      a numpy array.\n",
      "     |      \n",
      "     |      Row indices as in pandas data frames are supported, and added to the\n",
      "     |      returned prediction.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Results:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.ResultMixin:\n",
      "     |  \n",
      "     |  bootstrap(self, nrep=100, method='nm', disp=0, store=1)\n",
      "     |      simple bootstrap to get mean and variance of estimator\n",
      "     |      \n",
      "     |      see notes\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      nrep : int\n",
      "     |          number of bootstrap replications\n",
      "     |      method : str\n",
      "     |          optimization method to use\n",
      "     |      disp : bool\n",
      "     |          If true, then optimization prints results\n",
      "     |      store : bool\n",
      "     |          If true, then parameter estimates for all bootstrap iterations\n",
      "     |          are attached in self.bootstrap_results\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : ndarray\n",
      "     |          mean of parameter estimates over bootstrap replications\n",
      "     |      std : ndarray\n",
      "     |          standard deviation of parameter estimates over bootstrap\n",
      "     |          replications\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This was mainly written to compare estimators of the standard errors of\n",
      "     |      the parameter estimates.  It uses independent random sampling from the\n",
      "     |      original endog and exog, and therefore is only correct if observations\n",
      "     |      are independently distributed.\n",
      "     |      \n",
      "     |      This will be moved to apply only to models with independently\n",
      "     |      distributed observations.\n",
      "     |  \n",
      "     |  get_nlfun(self, fun)\n",
      "     |      get_nlfun\n",
      "     |      \n",
      "     |      This is not Implemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.ResultMixin:\n",
      "     |  \n",
      "     |  bsejac\n",
      "     |      standard deviation of parameter estimates based on covjac\n",
      "     |  \n",
      "     |  bsejhj\n",
      "     |      standard deviation of parameter estimates based on covHJH\n",
      "     |  \n",
      "     |  covjac\n",
      "     |      covariance of parameters based on outer product of jacobian of\n",
      "     |      log-likelihood\n",
      "     |  \n",
      "     |  covjhj\n",
      "     |      covariance of parameters based on HJJH\n",
      "     |      \n",
      "     |      dot product of Hessian, Jacobian, Jacobian, Hessian of likelihood\n",
      "     |      \n",
      "     |      name should be covhjh\n",
      "     |  \n",
      "     |  df_modelwc\n",
      "     |      Model WC\n",
      "     |  \n",
      "     |  hessv\n",
      "     |      cached Hessian of log-likelihood\n",
      "     |  \n",
      "     |  score_obsv\n",
      "     |      cached Jacobian of log-likelihood\n",
      "    \n",
      "    class MixedLMResultsWrapper(statsmodels.base.model.LikelihoodResultsWrapper)\n",
      "     |  MixedLMResultsWrapper(results)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MixedLMResultsWrapper\n",
      "     |      statsmodels.base.model.LikelihoodResultsWrapper\n",
      "     |      statsmodels.base.wrapper.ResultsWrapper\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodResultsWrapper:\n",
      "     |  \n",
      "     |  conf_int(self, alpha=0.05, cols=None)\n",
      "     |      conf_int(self, alpha=0.05, cols=None)\n",
      "     |      \n",
      "     |      Construct confidence interval for the fitted parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : float, optional\n",
      "     |          The significance level for the confidence interval. The default\n",
      "     |          `alpha` = .05 returns a 95% confidence interval.\n",
      "     |      cols : array_like, optional\n",
      "     |          Specifies which confidence intervals to return.\n",
      "     |      \n",
      "     |      .. deprecated: 0.13\n",
      "     |      \n",
      "     |         cols is deprecated and will be removed after 0.14 is released.\n",
      "     |         cols only works when inputs are NumPy arrays and will fail\n",
      "     |         when using pandas Series or DataFrames as input. You can\n",
      "     |         subset the confidence intervals using slices.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          Each row contains [lower, upper] limits of the confidence interval\n",
      "     |          for the corresponding parameter. The first column contains all\n",
      "     |          lower, the second column contains all upper limits.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The confidence interval is based on the standard normal distribution\n",
      "     |      if self.use_t is False. If self.use_t is True, then uses a Student's t\n",
      "     |      with self.df_resid_inference (or self.df_resid if df_resid_inference is\n",
      "     |      not defined) degrees of freedom.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> results.conf_int()\n",
      "     |      array([[-5496529.48322745, -1467987.78596704],\n",
      "     |             [    -177.02903529,      207.15277984],\n",
      "     |             [      -0.1115811 ,        0.03994274],\n",
      "     |             [      -3.12506664,       -0.91539297],\n",
      "     |             [      -1.5179487 ,       -0.54850503],\n",
      "     |             [      -0.56251721,        0.460309  ],\n",
      "     |             [     798.7875153 ,     2859.51541392]])\n",
      "     |      \n",
      "     |      >>> results.conf_int(cols=(2,3))\n",
      "     |      array([[-0.1115811 ,  0.03994274],\n",
      "     |             [-3.12506664, -0.91539297]])\n",
      "     |  \n",
      "     |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      \n",
      "     |      Compute the variance/covariance matrix.\n",
      "     |      \n",
      "     |      The variance/covariance matrix can be of a linear contrast of the\n",
      "     |      estimated parameters or all params multiplied by scale which will\n",
      "     |      usually be an estimate of sigma^2.  Scale is assumed to be a scalar.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array_like\n",
      "     |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      "     |      column : array_like, optional\n",
      "     |          Must be used on its own.  Can be 0d or 1d see below.\n",
      "     |      scale : float, optional\n",
      "     |          Can be specified or not.  Default is None, which means that\n",
      "     |          the scale argument is taken from the model.\n",
      "     |      cov_p : ndarray, optional\n",
      "     |          The covariance of the parameters. If not provided, this value is\n",
      "     |          read from `self.normalized_cov_params` or\n",
      "     |          `self.cov_params_default`.\n",
      "     |      other : array_like, optional\n",
      "     |          Can be used when r_matrix is specified.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The covariance matrix of the parameter estimates or of linear\n",
      "     |          combination of parameter estimates. See Notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      (The below are assumed to be in matrix notation.)\n",
      "     |      \n",
      "     |      If no argument is specified returns the covariance matrix of a model\n",
      "     |      ``(scale)*(X.T X)^(-1)``\n",
      "     |      \n",
      "     |      If contrast is specified it pre and post-multiplies as follows\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      "     |      \n",
      "     |      If contrast and other are specified returns\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      "     |      \n",
      "     |      If column is specified returns\n",
      "     |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      "     |      \n",
      "     |      OR\n",
      "     |      \n",
      "     |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __getattribute__(self, attr)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, results)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __setstate__(self, dict_)\n",
      "     |  \n",
      "     |  save(self, fname, remove_data=False)\n",
      "     |      Save a pickle of this instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : {str, handle}\n",
      "     |          Either a filename or a valid file handle.\n",
      "     |      remove_data : bool\n",
      "     |          If False (default), then the instance is pickled without changes.\n",
      "     |          If True, then all arrays with length nobs are set to None before\n",
      "     |          pickling. See the remove_data method.\n",
      "     |          In some cases not all arrays will be set to None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      "     |  \n",
      "     |  load(fname) from builtins.type\n",
      "     |      Load a pickled results instance\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |         Loading pickled models is not secure against erroneous or\n",
      "     |         maliciously constructed data. Never unpickle data received from\n",
      "     |         an untrusted or unauthenticated source.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : {str, handle}\n",
      "     |          A string filename or a file handle.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          The unpickled results instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class VCSpec(builtins.object)\n",
      "     |  VCSpec(names, colnames, mats)\n",
      "     |  \n",
      "     |  Define the variance component structure of a multilevel model.\n",
      "     |  \n",
      "     |  An instance of the class contains three attributes:\n",
      "     |  \n",
      "     |  - names : names[k] is the name of variance component k.\n",
      "     |  \n",
      "     |  - mats : mats[k][i] is the design matrix for group index\n",
      "     |    i in variance component k.\n",
      "     |  \n",
      "     |  - colnames : colnames[k][i] is the list of column names for\n",
      "     |    mats[k][i].\n",
      "     |  \n",
      "     |  The groups in colnames and mats must be in sorted order.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, names, colnames, mats)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    norm = <scipy.stats._continuous_distns.norm_gen object>\n",
      "        A normal continuous random variable.\n",
      "        \n",
      "        The location (``loc``) keyword specifies the mean.\n",
      "        The scale (``scale``) keyword specifies the standard deviation.\n",
      "        \n",
      "        As an instance of the `rv_continuous` class, `norm` object inherits from it\n",
      "        a collection of generic methods (see below for the full list),\n",
      "        and completes them with details specific for this particular distribution.\n",
      "        \n",
      "        Methods\n",
      "        -------\n",
      "        rvs(loc=0, scale=1, size=1, random_state=None)\n",
      "            Random variates.\n",
      "        pdf(x, loc=0, scale=1)\n",
      "            Probability density function.\n",
      "        logpdf(x, loc=0, scale=1)\n",
      "            Log of the probability density function.\n",
      "        cdf(x, loc=0, scale=1)\n",
      "            Cumulative distribution function.\n",
      "        logcdf(x, loc=0, scale=1)\n",
      "            Log of the cumulative distribution function.\n",
      "        sf(x, loc=0, scale=1)\n",
      "            Survival function  (also defined as ``1 - cdf``, but `sf` is sometimes more accurate).\n",
      "        logsf(x, loc=0, scale=1)\n",
      "            Log of the survival function.\n",
      "        ppf(q, loc=0, scale=1)\n",
      "            Percent point function (inverse of ``cdf`` --- percentiles).\n",
      "        isf(q, loc=0, scale=1)\n",
      "            Inverse survival function (inverse of ``sf``).\n",
      "        moment(order, loc=0, scale=1)\n",
      "            Non-central moment of the specified order.\n",
      "        stats(loc=0, scale=1, moments='mv')\n",
      "            Mean('m'), variance('v'), skew('s'), and/or kurtosis('k').\n",
      "        entropy(loc=0, scale=1)\n",
      "            (Differential) entropy of the RV.\n",
      "        fit(data)\n",
      "            Parameter estimates for generic data.\n",
      "            See `scipy.stats.rv_continuous.fit <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.fit.html#scipy.stats.rv_continuous.fit>`__ for detailed documentation of the\n",
      "            keyword arguments.\n",
      "        expect(func, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      "            Expected value of a function (of one argument) with respect to the distribution.\n",
      "        median(loc=0, scale=1)\n",
      "            Median of the distribution.\n",
      "        mean(loc=0, scale=1)\n",
      "            Mean of the distribution.\n",
      "        var(loc=0, scale=1)\n",
      "            Variance of the distribution.\n",
      "        std(loc=0, scale=1)\n",
      "            Standard deviation of the distribution.\n",
      "        interval(confidence, loc=0, scale=1)\n",
      "            Confidence interval with equal areas around the median.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function for `norm` is:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            f(x) = \\frac{\\exp(-x^2/2)}{\\sqrt{2\\pi}}\n",
      "        \n",
      "        for a real number :math:`x`.\n",
      "        \n",
      "        The probability density above is defined in the \"standardized\" form. To shift\n",
      "        and/or scale the distribution use the ``loc`` and ``scale`` parameters.\n",
      "        Specifically, ``norm.pdf(x, loc, scale)`` is identically\n",
      "        equivalent to ``norm.pdf(y) / scale`` with\n",
      "        ``y = (x - loc) / scale``. Note that shifting the location of a distribution\n",
      "        does not make it a \"noncentral\" distribution; noncentral generalizations of\n",
      "        some distributions are available in separate classes.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import norm\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> fig, ax = plt.subplots(1, 1)\n",
      "        \n",
      "        Calculate the first four moments:\n",
      "        \n",
      "        \n",
      "        >>> mean, var, skew, kurt = norm.stats(moments='mvsk')\n",
      "        \n",
      "        Display the probability density function (``pdf``):\n",
      "        \n",
      "        >>> x = np.linspace(norm.ppf(0.01),\n",
      "        ...                 norm.ppf(0.99), 100)\n",
      "        >>> ax.plot(x, norm.pdf(x),\n",
      "        ...        'r-', lw=5, alpha=0.6, label='norm pdf')\n",
      "        \n",
      "        Alternatively, the distribution object can be called (as a function)\n",
      "        to fix the shape, location and scale parameters. This returns a \"frozen\"\n",
      "        RV object holding the given parameters fixed.\n",
      "        \n",
      "        Freeze the distribution and display the frozen ``pdf``:\n",
      "        \n",
      "        >>> rv = norm()\n",
      "        >>> ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
      "        \n",
      "        Check accuracy of ``cdf`` and ``ppf``:\n",
      "        \n",
      "        >>> vals = norm.ppf([0.001, 0.5, 0.999])\n",
      "        >>> np.allclose([0.001, 0.5, 0.999], norm.cdf(vals))\n",
      "        True\n",
      "        \n",
      "        Generate random numbers:\n",
      "        \n",
      "        >>> r = norm.rvs(size=1000)\n",
      "        \n",
      "        And compare the histogram:\n",
      "        \n",
      "        >>> ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
      "        >>> ax.legend(loc='best', frameon=False)\n",
      "        >>> plt.show()\n",
      "\n",
      "FILE\n",
      "    /home/tekim/haha/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(statsmodels.regression.mixed_linear_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['length', 'height', 'width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['length', 'height', 'width'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = ['length']\n",
    "x_cols = ['height','width']\n",
    "X = df[x_cols].values\n",
    "y = df[y_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.892857</td>\n",
       "      <td>7.862143</td>\n",
       "      <td>4.745536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.021668</td>\n",
       "      <td>2.878343</td>\n",
       "      <td>1.775006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.400000</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>1.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.825000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>3.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.300000</td>\n",
       "      <td>6.920000</td>\n",
       "      <td>4.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36.625000</td>\n",
       "      <td>10.850000</td>\n",
       "      <td>6.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>8.140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          length     height      width\n",
       "count  56.000000  56.000000  56.000000\n",
       "mean   27.892857   7.862143   4.745536\n",
       "std     9.021668   2.878343   1.775006\n",
       "min     8.400000   2.110000   1.410000\n",
       "25%    21.825000   5.690000   3.520000\n",
       "50%    25.300000   6.920000   4.155000\n",
       "75%    36.625000  10.850000   6.450000\n",
       "max    44.000000  12.800000   8.140000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt(4)\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.399838524074895"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(27.892857 - 7.862143) / ((9.021668 - 2.878343)/ math.sqrt(56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 length   R-squared:                       0.971\n",
      "Model:                            OLS   Adj. R-squared:                  0.971\n",
      "Method:                 Least Squares   F-statistic:                     1837.\n",
      "Date:                Thu, 09 Mar 2023   Prob (F-statistic):           2.20e-43\n",
      "Time:                        16:24:37   Log-Likelihood:                -102.57\n",
      "No. Observations:                  56   AIC:                             209.1\n",
      "Df Residuals:                      54   BIC:                             213.2\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.6047      0.603      5.980      0.000       2.396       4.813\n",
      "height         3.0893      0.072     42.862      0.000       2.945       3.234\n",
      "==============================================================================\n",
      "Omnibus:                        0.547   Durbin-Watson:                   1.688\n",
      "Prob(Omnibus):                  0.761   Jarque-Bera (JB):                0.553\n",
      "Skew:                          -0.221   Prob(JB):                        0.759\n",
      "Kurtosis:                       2.796   Cond. No.                         24.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# model = smf.ols(\"length ~ height\",data=df)\n",
    "print(smf.ols(\"length ~ height\",data=df).fit().summary())\n",
    "# print(smf.ols(\"Lottery ~ Literacy\", data=df).fit().summary())\n",
    "# result = model.fit()\n",
    "# result.predict([df[x_cols]])\n",
    "# print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.892857</td>\n",
       "      <td>7.862143</td>\n",
       "      <td>4.745536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.021668</td>\n",
       "      <td>2.878343</td>\n",
       "      <td>1.775006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.400000</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>1.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.825000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>3.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.300000</td>\n",
       "      <td>6.920000</td>\n",
       "      <td>4.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36.625000</td>\n",
       "      <td>10.850000</td>\n",
       "      <td>6.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>8.140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          length     height      width\n",
       "count  56.000000  56.000000  56.000000\n",
       "mean   27.892857   7.862143   4.745536\n",
       "std     9.021668   2.878343   1.775006\n",
       "min     8.400000   2.110000   1.410000\n",
       "25%    21.825000   5.690000   3.520000\n",
       "50%    25.300000   6.920000   4.155000\n",
       "75%    36.625000  10.850000   6.450000\n",
       "max    44.000000  12.800000   8.140000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=24.161941167242333, pvalue=5.7685997696079625e-31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ttest_rel(df['length'],df['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.829015634041385, 3.986452287406845e-30, 110.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsmodels.stats.weightstats.ttest_ind(x1=df['length'],x2=df['height'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsmodels.stats.weightstats. (x1=df['length'],x2=df['height'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=15.829015634041392, pvalue=3.986452287406675e-30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ttest_ind(df['length'],df['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.390493502224"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9.021668**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5217391304347826"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2/2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.829015295420351"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(27.892857 - 7.862143) / math.sqrt((9.021668**2) /56 + (2.878343**2)/56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ttost_paired() missing 2 required positional arguments: 'low' and 'upp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/tekim/data/tekim/datapython/AI_SOLAB/adp/study_1.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/tekim/data/tekim/datapython/AI_SOLAB/adp/study_1.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m statsmodels\u001b[39m.\u001b[39;49mstats\u001b[39m.\u001b[39;49mweightstats\u001b[39m.\u001b[39;49mttost_paired(x1\u001b[39m=\u001b[39;49mdf[\u001b[39m'\u001b[39;49m\u001b[39mlength\u001b[39;49m\u001b[39m'\u001b[39;49m],x2\u001b[39m=\u001b[39;49mdf[\u001b[39m'\u001b[39;49m\u001b[39mheight\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m# return (test-statistic,pvalue,deg of freedom)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: ttost_paired() missing 2 required positional arguments: 'low' and 'upp'"
     ]
    }
   ],
   "source": [
    "statsmodels.stats.weightstats.ttost_paired(x1=df['length'],x2=df['height']) # return (test-statistic,pvalue,deg of freedom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value  4.2726668647574684e-08\n",
      "statics  328.2922980307293\n"
     ]
    }
   ],
   "source": [
    "# 파이썬에서는 단일 표본 분산검정 or 단일 표본 카이검정 패키지가 없어서 커스텀해서 사용 / https://blog.naver.com/breezehome50/222334155742\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "def chi_var_test(x, var0, alternative='two-sided'):\n",
    "    lenth = len(x)\n",
    "    chi_stat = (lenth-1) * np.var(x, ddof=1) / var0\n",
    "    \n",
    "    temp = stats.chi2.cdf(chi_stat, lenth-1)\n",
    "    if alternative == 'two-sided':\n",
    "        pval = 2*(1-temp) if temp > 0.5 else 2*temp\n",
    "    elif alternative == 'greater':\n",
    "        pval = 1 - temp\n",
    "    elif alternative == 'less':\n",
    "        pval = temp\n",
    "    else:\n",
    "        print(\"ERROR\")\n",
    "        \n",
    "    return chi_stat, pval\n",
    "\n",
    "\n",
    "# 1. 귀무가설 : 분산은 1.3이다. / 연구가설 : 분산은 1.3이 아니다\n",
    "\n",
    "# 2. 양측 검정 시행\n",
    "chi_stat, p_val = chi_var_test(df['content'], var0=1.3, alternative='two-sided')\n",
    "print('p-value ',p_val)\n",
    "print('statics ',chi_stat)\n",
    "\n",
    "# 3. 검정통계량\n",
    "# p-value는 4.2e-8로 유의수준 0.05수준에서 귀무가설을 기각하고 연구가설을 채택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
