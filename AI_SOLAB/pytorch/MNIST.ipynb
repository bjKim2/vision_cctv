{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2df512b9310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs= 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "mnist_test = dsets.MNIST(root='MNIST_data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: MNIST_data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=mnist_train,\n",
    "    batch_size = batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rlaxo\\vision_cctv\\AI_SOLAB\\pytorch\\MNIST.ipynb ì…€ 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rlaxo/vision_cctv/AI_SOLAB/pytorch/MNIST.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_loader[\u001b[39m1\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data_loader[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: MNIST_data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cnn(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.keep_prob = 0.5\n",
    "#         self.layer1 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(1,16,3,1,padding=1),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.MaxPool2d(2,stride=1)\n",
    "#         )\n",
    "#         self.layer2 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(16,32,3,1,1),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.MaxPool2d(2, stride=1)\n",
    "#         )\n",
    "#         self.layer3 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(32,32,3,1,1),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.MaxPool2d(2,stride=1)\n",
    "#         )\n",
    "#         self.fc1 = torch.nn.Linear(4 * 4 * 8, 10, bias = True)\n",
    "#         # torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "#         # self.layer4 = torch.nn.Sequential(\n",
    "#         #     self.fc1,\n",
    "#         #     torch.nn.SiLU(),\n",
    "#         #     torch.nn.Dropout( p = 1 - self.keep_prob)\n",
    "#         # )\n",
    "#         # self.fc2 = torch.nn.Linear(625,10,bias = True)\n",
    "#         # torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         out = self.layer1(x)\n",
    "#         out = self.layer2(out)\n",
    "#         out = self.layer3(out)\n",
    "#         # out = out.view(out.size(0), -1)\n",
    "#         # out = self.layer4(out)\n",
    "#         out = self.fc1(out)\n",
    "#         return out\n",
    "\n",
    "\n",
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1,32,3,1,padding=1),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.MaxPool2d(2,stride=1)\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32,64,3,1,1),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=1)\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64,128,3,1,1),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.MaxPool2d(2,2,1)\n",
    "        )\n",
    "        # self.fc1 = torch.nn.Linear(4 * 4 * 32, 10, bias = True)\n",
    "        self.fc1 = torch.nn.Linear(25088, 10, bias = True)\n",
    "        # torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        # self.layer4 = torch.nn.Sequential(\n",
    "        #     self.fc1,\n",
    "        #     torch.nn.SiLU(),\n",
    "        #     torch.nn.Dropout( p = 1 - self.keep_prob)\n",
    "        # )\n",
    "        # self.fc2 = torch.nn.Linear(625,10,bias = True)\n",
    "        # torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        out = self.layer1(x)\n",
    "        # print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "        # print(out.shape)\n",
    "        out = self.layer3(out)\n",
    "        # print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(out.shape)\n",
    "        # out = self.layer4(out)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_batch = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 1.7196846\n",
      "[Epoch:    2] cost = 0.0964167342\n",
      "[Epoch:    3] cost = 0.0665245429\n",
      "[Epoch:    4] cost = 0.0572907552\n",
      "[Epoch:    5] cost = 0.0520264506\n",
      "[Epoch:    6] cost = 0.0450050496\n",
      "[Epoch:    7] cost = 0.0411917195\n",
      "[Epoch:    8] cost = 0.043069765\n",
      "[Epoch:    9] cost = 0.0476047732\n",
      "[Epoch:   10] cost = 0.0435550772\n",
      "[Epoch:   11] cost = 0.0396808945\n",
      "[Epoch:   12] cost = 0.052599676\n",
      "[Epoch:   13] cost = 0.046072457\n",
      "[Epoch:   14] cost = 0.062129572\n",
      "[Epoch:   15] cost = 0.0507975966\n",
      "[Epoch:   16] cost = 0.0505004115\n",
      "[Epoch:   17] cost = 0.0669750571\n",
      "[Epoch:   18] cost = 0.140460655\n",
      "[Epoch:   19] cost = 1.0090791\n",
      "[Epoch:   20] cost = 0.143159613\n",
      "[Epoch:   21] cost = 0.095900014\n",
      "[Epoch:   22] cost = 0.0712244064\n",
      "[Epoch:   23] cost = 0.0578233749\n",
      "[Epoch:   24] cost = 0.0610677227\n",
      "[Epoch:   25] cost = 0.0496310554\n",
      "[Epoch:   26] cost = 0.0429023765\n",
      "[Epoch:   27] cost = 0.0428903103\n",
      "[Epoch:   28] cost = 0.0379214436\n",
      "[Epoch:   29] cost = 0.0350372382\n",
      "[Epoch:   30] cost = 0.0308350362\n",
      "[Epoch:   31] cost = 0.0365965515\n",
      "[Epoch:   32] cost = 0.0418737642\n",
      "[Epoch:   33] cost = 0.0306228772\n",
      "[Epoch:   34] cost = 0.0402687229\n",
      "[Epoch:   35] cost = 0.0485242121\n",
      "[Epoch:   36] cost = 0.0452380031\n",
      "[Epoch:   37] cost = 0.036807932\n",
      "[Epoch:   38] cost = 0.0302355494\n",
      "[Epoch:   39] cost = 0.0467103906\n",
      "[Epoch:   40] cost = 0.036072813\n",
      "[Epoch:   41] cost = 0.0398070849\n",
      "[Epoch:   42] cost = 0.0301776286\n",
      "[Epoch:   43] cost = 0.0341595635\n",
      "[Epoch:   44] cost = 0.0276731532\n",
      "[Epoch:   45] cost = 0.0252451841\n",
      "[Epoch:   46] cost = 0.024075361\n",
      "[Epoch:   47] cost = 0.0386466905\n",
      "[Epoch:   48] cost = 0.03066222\n",
      "[Epoch:   49] cost = 0.0444101468\n",
      "[Epoch:   50] cost = 0.0247556716\n",
      "[Epoch:   51] cost = 0.0179006048\n",
      "[Epoch:   52] cost = 0.0229137968\n",
      "[Epoch:   53] cost = 0.0265973527\n",
      "[Epoch:   54] cost = 0.0238547977\n",
      "[Epoch:   55] cost = 0.028032504\n",
      "[Epoch:   56] cost = 0.0147647196\n",
      "[Epoch:   57] cost = 0.0138555728\n",
      "[Epoch:   58] cost = 0.0152266473\n",
      "[Epoch:   59] cost = 0.0166131314\n",
      "[Epoch:   60] cost = 4.14184618\n",
      "[Epoch:   61] cost = 2.30172515\n",
      "[Epoch:   62] cost = 2.3018105\n",
      "[Epoch:   63] cost = 2.30162001\n",
      "[Epoch:   64] cost = 2.30177641\n",
      "[Epoch:   65] cost = 2.30166674\n",
      "[Epoch:   66] cost = 2.30172443\n",
      "[Epoch:   67] cost = 2.30179667\n",
      "[Epoch:   68] cost = 2.30159545\n",
      "[Epoch:   69] cost = 2.30163622\n",
      "[Epoch:   70] cost = 2.30171657\n",
      "[Epoch:   71] cost = 2.30161381\n",
      "[Epoch:   72] cost = 2.30167174\n",
      "[Epoch:   73] cost = 2.30172729\n",
      "[Epoch:   74] cost = 2.30164528\n",
      "[Epoch:   75] cost = 2.30161071\n",
      "[Epoch:   76] cost = 2.30153871\n",
      "[Epoch:   77] cost = 2.30184603\n",
      "[Epoch:   78] cost = 2.30167699\n",
      "[Epoch:   79] cost = 2.30166054\n",
      "[Epoch:   80] cost = 2.30165839\n",
      "[Epoch:   81] cost = 2.30169487\n",
      "[Epoch:   82] cost = 2.30176806\n",
      "[Epoch:   83] cost = 2.30164862\n",
      "[Epoch:   84] cost = 2.30158138\n",
      "[Epoch:   85] cost = 2.30160379\n",
      "[Epoch:   86] cost = 2.3016727\n",
      "[Epoch:   87] cost = 2.30174828\n",
      "[Epoch:   88] cost = 2.30163836\n",
      "[Epoch:   89] cost = 2.30164289\n",
      "[Epoch:   90] cost = 2.30165029\n",
      "[Epoch:   91] cost = 2.30171895\n",
      "[Epoch:   92] cost = 2.3017838\n",
      "[Epoch:   93] cost = 2.30171347\n",
      "[Epoch:   94] cost = 5.63900471\n",
      "[Epoch:   95] cost = 2.30165792\n",
      "[Epoch:   96] cost = 2.30162454\n",
      "[Epoch:   97] cost = 2.3015871\n",
      "[Epoch:   98] cost = 2.30162764\n",
      "[Epoch:   99] cost = 2.3018229\n",
      "[Epoch:  100] cost = 2.30163574\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost/total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1 , avg_cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (default, Nov 23 2021, 15:27:38) \n[GCC 9.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
