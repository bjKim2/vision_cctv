{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(input_dim, putput_dim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_dim' is not defined"
     ]
    }
   ],
   "source": [
    "# model = nn.Linear(input_dim, putput_dim)\n",
    "# cost = F.mse_loss(prediction, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2e782c3b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f2d909e56d0>\n",
      "[Parameter containing:\n",
      "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4694], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print((model.parameters()))\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 0.000000\n",
      "Epoch  100/2000 Cost: 0.000000\n",
      "Epoch  200/2000 Cost: 0.000000\n",
      "Epoch  300/2000 Cost: 0.000000\n",
      "Epoch  400/2000 Cost: 0.000000\n",
      "Epoch  500/2000 Cost: 0.000000\n",
      "Epoch  600/2000 Cost: 0.000000\n",
      "Epoch  700/2000 Cost: 0.000000\n",
      "Epoch  800/2000 Cost: 0.000000\n",
      "Epoch  900/2000 Cost: 0.000000\n",
      "Epoch 1000/2000 Cost: 0.000000\n",
      "Epoch 1100/2000 Cost: 0.000000\n",
      "Epoch 1200/2000 Cost: 0.000000\n",
      "Epoch 1300/2000 Cost: 0.000000\n",
      "Epoch 1400/2000 Cost: 0.000000\n",
      "Epoch 1500/2000 Cost: 0.000000\n",
      "Epoch 1600/2000 Cost: 0.000000\n",
      "Epoch 1700/2000 Cost: 0.000000\n",
      "Epoch 1800/2000 Cost: 0.000000\n",
      "Epoch 1900/2000 Cost: 0.000000\n",
      "Epoch 2000/2000 Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    cost = F.mse_loss(prediction,y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 4일 때의 예측값 : tensor([[8.0000]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 4를 선언\n",
    "new_var =  torch.FloatTensor([[4.0]]) \n",
    "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) # forward 연산\n",
    "# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것\n",
    "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[2.0000]], requires_grad=True), Parameter containing:\n",
      "tensor([8.7017e-06], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2e782c3b90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((3,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2710], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 / 2000 , Cost : 31667.597656\n",
      "epoch : 100 / 2000 , Cost : 0.225988\n",
      "epoch : 200 / 2000 , Cost : 0.223910\n",
      "epoch : 300 / 2000 , Cost : 0.221930\n",
      "epoch : 400 / 2000 , Cost : 0.220059\n",
      "epoch : 500 / 2000 , Cost : 0.218270\n",
      "epoch : 600 / 2000 , Cost : 0.216571\n",
      "epoch : 700 / 2000 , Cost : 0.214955\n",
      "epoch : 800 / 2000 , Cost : 0.213413\n",
      "epoch : 900 / 2000 , Cost : 0.211949\n",
      "epoch : 1000 / 2000 , Cost : 0.210558\n",
      "epoch : 1100 / 2000 , Cost : 0.209237\n",
      "epoch : 1200 / 2000 , Cost : 0.207971\n",
      "epoch : 1300 / 2000 , Cost : 0.206764\n",
      "epoch : 1400 / 2000 , Cost : 0.205616\n",
      "epoch : 1500 / 2000 , Cost : 0.204527\n",
      "epoch : 1600 / 2000 , Cost : 0.203479\n",
      "epoch : 1700 / 2000 , Cost : 0.202487\n",
      "epoch : 1800 / 2000 , Cost : 0.201542\n",
      "epoch : 1900 / 2000 , Cost : 0.200638\n",
      "epoch : 2000 / 2000 , Cost : 0.199769\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    cost = F.mse_loss(prediction,y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'epoch : {epoch} / {nb_epochs} , Cost : {cost.squeeze():.6f}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.2305]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haha",
   "language": "python",
   "name": "haha"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
